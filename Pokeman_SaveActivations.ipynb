{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import loggingreporter \n",
    "\n",
    "cfg = {}\n",
    "cfg['SGD_BATCHSIZE']    = 64\n",
    "cfg['SGD_LEARNINGRATE'] = 0.001\n",
    "cfg['NUM_EPOCHS']       = 10000\n",
    "cfg['FULL_MI']          = True\n",
    "\n",
    "# cfg['ACTIVATION'] = 'tanh'\n",
    "cfg['ACTIVATION'] = 'relu'\n",
    "\n",
    "# How many hidden neurons to put into each of the layers\n",
    "cfg['LAYER_DIMS'] = [16, 16, 8]\n",
    "ARCH_NAME =  '-'.join(map(str,cfg['LAYER_DIMS']))\n",
    "\n",
    "# No validation data is created. Only TRAIN and TEST\n",
    "trn, tst = utils.get_pokeman()\n",
    "\n",
    "# Where to save activation and weights data\n",
    "cfg['SAVE_DIR'] = 'rawdata/' + cfg['ACTIVATION'] + '_' + ARCH_NAME \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should keep the initialization and optimizer the same across different experiments to remove other potential influences\n",
    "# IBnet uses truncatedNormal and Adam\n",
    "\n",
    "input_layer  = keras.layers.Input((trn.X.shape[1],))\n",
    "\n",
    "clayer = input_layer\n",
    "\n",
    "# Try L2norm, dropout here\n",
    "for n in cfg['LAYER_DIMS']:\n",
    "    clayer = keras.layers.Dense(n, \n",
    "                                activation=cfg['ACTIVATION'],\n",
    "                                kernel_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=1/np.sqrt(float(n)), seed=10),\n",
    "                                bias_initializer='zeros'\n",
    "#                                 kernel_regularizer=regularizers.l2(0.01) # add L2 norm regularization\n",
    "                               )(clayer)\n",
    "#     clayer = keras.layers.Dropout(0.1)(clayer)\n",
    "output_layer = keras.layers.Dense(trn.nb_classes, activation='softmax')(clayer)\n",
    "\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# sgd = keras.optimizers.SGD(lr=cfg['SGD_LEARNINGRATE'], decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1.0, clipvalue=0.5)\n",
    "sgd = keras.optimizers.SGD(lr=cfg['SGD_LEARNINGRATE'], momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def do_report(epoch):\n",
    "    # Only log activity for some epochs.  Mainly this is to make things run faster.\n",
    "    if epoch < 20:       # Log for all first 20 epochs\n",
    "        return True\n",
    "    elif epoch < 100:    # Then for every 5th epoch\n",
    "        return (epoch % 5 == 0)\n",
    "    elif epoch < 200:    # Then every 10th\n",
    "        return (epoch % 10 == 0)\n",
    "    else:                # Then every 100th\n",
    "        return (epoch % 100 == 0)\n",
    "    \n",
    "reporter = loggingreporter.LoggingReporter(cfg=cfg, \n",
    "                                          trn=trn, \n",
    "                                          tst=tst, \n",
    "                                          do_save_func=do_report)\n",
    "r = model.fit(x=trn.X, y=trn.Y, \n",
    "              verbose    = 2, \n",
    "              batch_size = cfg['SGD_BATCHSIZE'],\n",
    "              epochs     = cfg['NUM_EPOCHS'],\n",
    "              validation_split = 0.2,\n",
    "              shuffle = True,\n",
    "              # validation_data=(tst.X, tst.Y),\n",
    "              callbacks  = [reporter,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes insane time to run on my own laptop, but it works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
